{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Library Install\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "# !pip install numpy\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from operator import itemgetter\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "### 1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Once', 'RB'),\n",
       " ('there', 'EX'),\n",
       " ('were', 'VBD'),\n",
       " ('four', 'CD'),\n",
       " ('children', 'NNS'),\n",
       " ('whose', 'WP$'),\n",
       " ('names', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('Peter', 'NNP'),\n",
       " (',', ','),\n",
       " ('Susan', 'NNP'),\n",
       " (',', ','),\n",
       " ('Edmond', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('Lucy', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"Once there were four children whose names were Peter, Susan, Edmond, and Lucy.\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('can', 'MD'),\n",
       " ('is', 'VBZ'),\n",
       " ('difficult', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('open', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"This can is difficult to open.\")\n",
    "nltk.pos_tag(text)\n",
    "\n",
    "# the word 'can' is actually a noun in this case,but the tagger believes it to be a 'modal could, will'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "### 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "a.\tDoes it produce the same or different output?\n",
    "b.\tExplain any differences as best you can.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pattern\n",
    "from pattern.en import parse\n",
    "from pattern.en import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA    \n",
      "                                                              \n",
      "          Once   RB     ADVP    -      -      -      once     \n",
      "         there   EX     -       -      -      -      there    \n",
      "          were   VBD    VP      -      1      -      be       \n",
      "          four   CD     NP      OBJ    1      -      four     \n",
      "      children   NNS    NP ^    OBJ    1      -      child    \n",
      "         whose   WP$    -       -      -      -      whose    \n",
      "         names   NNS    NP      SBJ    2      -      name     \n",
      "          were   VBD    VP      -      2      -      be       \n",
      "         Peter   NNP    NP      OBJ    2      -      peter    \n",
      "             ,   ,      -       -      -      -      ,        \n",
      "         Susan   NNP    NP      -      -      -      susan    \n",
      "             ,   ,      -       -      -      -      ,        \n",
      "        Edmond   NNP    NP      -      -      -      edmond   \n",
      "             ,   ,      -       -      -      -      ,        \n",
      "           and   CC     -       -      -      -      and      \n",
      "          Lucy   NNP    NP      -      -      -      lucy     \n",
      "             .   .      -       -      -      -      .        \n"
     ]
    }
   ],
   "source": [
    "text = \"Once there were four children whose names were Peter, Susan, Edmond, and Lucy.\"\n",
    "pprint(parse(text, relations=True, lemmata=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA       \n",
      "                                                                 \n",
      "          This   DT     -       -      -      -      this        \n",
      "           can   MD     VP      -      -      -      can         \n",
      "            is   VBZ    VP ^    -      -      -      be          \n",
      "     difficult   JJ     ADJP    -      -      -      difficult   \n",
      "            to   TO     VP      -      -      -      to          \n",
      "          open   VB     VP ^    -      -      -      open        \n",
      "             .   .      -       -      -      -      .           \n"
     ]
    }
   ],
   "source": [
    "text = \"This can is difficult to open.\"\n",
    "pprint(parse(text, relations=True, lemmata=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I thought this was a really neat excercise. The results were the same for both taggers and sentences. I preferred the output of the Pattern tagger since it provides additional information (chunk/role/id/pnp/lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "### 3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "a.\tLooking at the Penn tag set, manually POS tag the sentence yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meat shortages feared, Russia suspected as hackers shutter JBS plants after targeting Colonial pipeline\n"
     ]
    }
   ],
   "source": [
    "text = \"Meat shortages feared, Russia suspected as hackers shutter JBS plants after targeting Colonial pipeline\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meat = NN, shortages = NNS, feared = VBD, Russia = NNP, suspected = VBD, as = IN, hackers = NNS,shutter = NN, JBS = NNP, plants = NNS, after = IN, targeting = VBD, colonial = NNP, pipeline = NNP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Meat', 'NN'),\n",
       " ('shortages', 'NNS'),\n",
       " ('feared', 'VBN'),\n",
       " (',', ','),\n",
       " ('Russia', 'NNP'),\n",
       " ('suspected', 'VBD'),\n",
       " ('as', 'IN'),\n",
       " ('hackers', 'NNS'),\n",
       " ('shutter', 'VBP'),\n",
       " ('JBS', 'NNP'),\n",
       " ('plants', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('targeting', 'VBG'),\n",
       " ('Colonial', 'NNP'),\n",
       " ('pipeline', 'NN')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = word_tokenize(text)\n",
    "nltk.pos_tag(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG       CHUNK   ROLE   ID     PNP    LEMMA      \n",
      "                                                                   \n",
      "          Meat   JJ        NP      SBJ    1      -      meat       \n",
      "     shortages   NNS       NP ^    SBJ    1      -      shortage   \n",
      "        feared   VBN       VP      -      1      -      fear       \n",
      "             ,   ,         -       -      -      -      ,          \n",
      "        Russia   NNP-LOC   NP      SBJ    2      -      russia     \n",
      "     suspected   VBD       VP      -      2      -      suspect    \n",
      "            as   IN        PP      -      -      PNP    as         \n",
      "       hackers   NNS       NP      -      -      PNP    hacker     \n",
      "       shutter   NN        NP ^    -      -      PNP    shutter    \n",
      "           JBS   NN        NP ^    -      -      PNP    jbs        \n",
      "        plants   NNS       NP ^    -      -      PNP    plant      \n",
      "         after   IN        PP      -      -      PNP    after      \n",
      "     targeting   VBG       VP      -      3      PNP    target     \n",
      "      Colonial   NNP       NP      OBJ    3      PNP    colonial   \n",
      "      pipeline   NN        NP ^    OBJ    3      PNP    pipeline   \n"
     ]
    }
   ],
   "source": [
    "pprint(parse(text, relations=True, lemmata=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neither tagger produced the same result as what I tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.\tExplain any differences between the two taggers and your manual tagging as much as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both taggers were different from each other and what I manually tagged. They were minor differences mainly around verb and noun tense but overall they shared many commonalities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
